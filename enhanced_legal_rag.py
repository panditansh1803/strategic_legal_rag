import os
import json
import uuid
import hashlib
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict
import re
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from functools import lru_cache

# Core dependencies
import pandas as pd
import numpy as np
import sqlite3
from cachetools import TTLCache
from pathlib import Path

# Document processing
try:
    import PyPDF2
    HAS_PDF = True
except ImportError:
    HAS_PDF = False

try:
    import docx
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

# Web scraping and API calls
import requests
import urllib.parse
try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False

try:
    import feedparser
    HAS_FEEDPARSER = True
except ImportError:
    HAS_FEEDPARSER = False

# Enhanced NLP processing
try:
    import spacy
    HAS_SPACY = True
except ImportError:
    HAS_SPACY = False

try:
    import nltk
    HAS_NLTK = True
except ImportError:
    HAS_NLTK = False

HAS_NLP = HAS_SPACY and HAS_NLTK

# UI and visualization
import streamlit as st
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

# Vector database
try:
    import chromadb
    HAS_CHROMADB = True
except ImportError:
    HAS_CHROMADB = False

# Sentence transformers
try:
    from sentence_transformers import SentenceTransformer
    HAS_EMBEDDINGS = True
except ImportError:
    HAS_EMBEDDINGS = False

# AI APIs
try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# Enhanced logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global constants and configurations
SUPPORTED_JURISDICTIONS = {
    'India': ['Supreme Court of India', 'High Courts', 'District Courts', 'Tribunals'],
    'United States': ['US Supreme Court', 'Circuit Courts', 'District Courts', 'State Courts'],
    'United Kingdom': ['House of Lords', 'Court of Appeal', 'High Court', 'Crown Court'],
    'Canada': ['Supreme Court of Canada', 'Federal Court', 'Provincial Courts'],
    'Australia': ['High Court of Australia', 'Federal Court', 'State Courts'],
    'Singapore': ['Court of Appeal', 'High Court', 'District Court'],
    'Hong Kong': ['Court of Final Appeal', 'High Court', 'District Court'],
    'European Union': ['European Court of Justice', 'European Court of Human Rights'],
    'International': ['International Court of Justice', 'International Criminal Court']
}

LEGAL_AREAS = {
    'Constitutional Law': ['fundamental rights', 'judicial review', 'constitutional amendments'],
    'Criminal Law': ['criminal procedure', 'evidence law', 'sentencing', 'appeals'],
    'Civil Law': ['contracts', 'torts', 'property law', 'family law'],
    'Corporate Law': ['company law', 'securities', 'mergers', 'compliance'],
    'Intellectual Property': ['patents', 'trademarks', 'copyrights', 'trade secrets'],
    'Employment Law': ['labor rights', 'workplace disputes', 'discrimination'],
    'Tax Law': ['income tax', 'corporate tax', 'international taxation'],
    'Environmental Law': ['pollution control', 'climate law', 'environmental impact'],
    'International Law': ['treaties', 'diplomatic immunity', 'trade law'],
    'Human Rights Law': ['civil liberties', 'fundamental freedoms', 'discrimination']
}

# Comprehensive Legal Knowledge Base
COMPREHENSIVE_LEGAL_KNOWLEDGE = {
    'contract_law': {
        'breach_of_contract': {
            'definition': 'A breach of contract occurs when one party fails to perform any duty or obligation specified in a valid contract.',
            'elements': ['Valid contract existed', 'Performance was due', 'Breach occurred', 'Damages resulted from breach'],
            'types': ['Material breach', 'Minor breach', 'Fundamental breach', 'Anticipatory breach'],
            'remedies': ['Compensatory damages', 'Consequential damages', 'Liquidated damages', 'Specific performance', 'Rescission', 'Restitution'],
            'procedures': ['Document the breach thoroughly', 'Calculate actual damages incurred', 'Send formal demand notice', 'Attempt good faith negotiations', 'File lawsuit if necessary', 'Gather supporting evidence'],
            'success_factors': ['Clear unambiguous contract terms', 'Strong evidence of breach', 'Quantifiable damages', 'Timely legal action', 'Proper contract formation', 'Lack of valid defenses'],
            'challenges': ['Proving materiality of breach', 'Calculating consequential damages', 'Statute of limitations issues', 'Contributory negligence claims', 'Force majeure defenses', 'Mitigation of damages requirements'],
            'timeline': '6-18 months for resolution through litigation',
            'costs': {'consultation': 15000, 'simple_case': 100000, 'complex_case': 500000, 'trial': 1000000},
            'recommendations': ['Document all communications', 'Preserve evidence', 'Seek legal counsel early', 'Consider alternative dispute resolution']
        }
    },
    'employment_law': {
        'wrongful_termination': {
            'definition': 'Illegal dismissal violating employment law, contract terms, or public policy.',
            'elements': ['Employment relationship existed', 'Termination occurred', 'Termination was unlawful', 'Damages resulted'],
            'procedures': ['Document termination circumstances', 'Gather employment records', 'File unemployment benefits', 'Consult employment attorney', 'File EEOC charge if discrimination', 'Preserve evidence'],
            'timeline': '180 days to file EEOC charge, 18-36 months for litigation',
            'costs': {'eeoc_filing': 0, 'attorney_fees': 200000, 'complex_case': 500000, 'trial': 1000000},
            'recommendations': ['Act quickly within deadlines', 'Document everything', 'File for unemployment benefits', 'Consult with employment attorney']
        }
    },
    'criminal_law': {
        'defense_strategies': {
            'definition': 'Legal strategies to defend against criminal charges through constitutional, substantive, and procedural defenses.',
            'elements': ['Valid charges filed', 'Defendant rights', 'Evidence evaluation', 'Defense preparation'],
            'procedures': ['Arraignment', 'Discovery', 'Pre-trial motions', 'Plea negotiations', 'Trial preparation', 'Sentencing'],
            'timeline': {'misdemeanor': '3-6 months', 'felony': '6-18 months', 'complex_cases': '2+ years'},
            'costs': {'misdemeanor': 75000, 'felony': 250000, 'serious_felony': 750000, 'capital_case': 2000000},
            'recommendations': ['Exercise right to counsel', 'Remain silent', 'Document all interactions', 'Prepare strong defense']
        }
    }
}

@dataclass
class EnhancedSimilarCase:
    """Enhanced similar case with comprehensive analysis"""
    case_id: str
    case_name: str
    facts: str
    legal_issues: List[str]
    court_decision: str
    winning_arguments: List[str]
    losing_arguments: List[str]
    key_evidence: List[str]
    case_outcome: str
    similarity_score: float
    jurisdiction: str
    precedential_value: str
    strategic_lessons: List[str]
    distinguishing_factors: List[str]
    citation: Optional[str] = None
    court: Optional[str] = None
    date_decided: Optional[str] = None
    url: Optional[str] = None

@dataclass
class ComprehensiveLegalAnswer:
    """Comprehensive legal answer structure"""
    question: str
    answer: str
    confidence_score: float
    legal_area: str
    jurisdiction: str
    sources: List[Dict[str, Any]]
    related_cases: List[EnhancedSimilarCase]
    applicable_statutes: List[Dict[str, str]]
    procedural_requirements: List[str]
    potential_challenges: List[str]
    success_probability: float
    alternative_approaches: List[str]
    cost_estimates: Dict[str, Any]
    timeline_estimates: Dict[str, str]
    expert_recommendations: List[str]
    follow_up_questions: List[str]
    fact_check_status: str
    last_updated: str

def get_api_key_safe(key_name: str) -> Optional[str]:
    """Safely get API key with multiple fallback methods"""
    try:
        # Method 1: Streamlit secrets
        if hasattr(st, 'secrets') and key_name in st.secrets:
            return st.secrets[key_name]
    except:
        pass
    
    try:
        # Method 2: Environment variables
        return os.getenv(key_name)
    except:
        pass
    
    return None

async def query_perplexity_bulletproof(prompt: str, model: str = "llama-3.1-sonar-small-128k-online") -> Optional[str]:
    """Bulletproof Perplexity API query - never crashes the system"""
    try:
        api_key = get_api_key_safe('PERPLEXITY_API_KEY')
        if not api_key:
            logger.warning("Perplexity API key not found")
            return None

        url = "https://api.perplexity.ai/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": 2000,
            "stream": False
        }
        
        for attempt in range(3):
            try:
                timeout = aiohttp.ClientTimeout(total=30)
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.post(url, headers=headers, json=payload) as response:
                        if response.status == 200:
                            data = await response.json()
                            return data['choices'][0]['message']['content']
                        elif response.status == 429:
                            wait_time = 2 ** attempt
                            logger.warning(f"Perplexity rate limited, waiting {wait_time}s...")
                            await asyncio.sleep(wait_time)
                        elif response.status == 401:
                            logger.error("Perplexity API key invalid")
                            return None
                        else:
                            logger.error(f"Perplexity API error {response.status}")
                            if attempt == 2:  # Last attempt
                                return None
            except asyncio.TimeoutError:
                logger.warning(f"Perplexity timeout on attempt {attempt + 1}")
            except Exception as e:
                logger.warning(f"Perplexity attempt {attempt + 1} failed: {e}")
            
            if attempt < 2:
                await asyncio.sleep(2 ** attempt)
        
        return None
    except Exception as e:
        logger.error(f"Perplexity query failed: {e}")
        return None

def query_gemini_bulletproof(prompt: str) -> Optional[str]:
    """Bulletproof Gemini query - never crashes the system"""
    try:
        if not HAS_GEMINI:
            return None
            
        api_key = get_api_key_safe('GOOGLE_API_KEY') or get_api_key_safe('GEMINI_API_KEY')
        if not api_key:
            logger.warning("Gemini API key not found")
            return None
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=2000,
                temperature=0.7,
            )
        )
        return response.text
    except Exception as e:
        logger.warning(f"Gemini query failed: {e}")
        return None

class AdvancedDocumentProcessor:
    """Enhanced document processor with AI-powered analysis - bulletproof version"""
    
    def __init__(self):
        self.nlp = self._init_nlp_models()
        
        # Enhanced legal patterns
        self.enhanced_citation_patterns = {
            'india': [
                r'AIR\s+\d{4}\s+SC\s+\d+',
                r'\(\d{4}\)\s+\d+\s+SCC\s+\d+',
                r'AIR\s+\d{4}\s+[A-Z]{2,8}\s+\d+',
                r'\d{4}\s+\(\d+\)\s+[A-Z]{3,8}\s+\d+',
                r'[A-Z\s&]+v\.\s+[A-Z\s&]+,?\s+AIR\s+\d{4}',
            ],
            'us': [
                r'\d+\s+U\.S\.\s+\d+',
                r'\d+\s+S\.Ct\.\s+\d+',
                r'\d+\s+F\.\d*d\s+\d+',
                r'\d+\s+F\.Supp\.\d*d\s+\d+',
                r'[A-Z\s&]+v\.\s+[A-Z\s&]+,?\s+\d+\s+U\.S\.',
            ],
            'uk': [
                r'\[\d{4}\]\s+UKHL\s+\d+',
                r'\[\d{4}\]\s+EWCA\s+Civ\s+\d+',
                r'\[\d{4}\]\s+EWHC\s+\d+',
                r'[A-Z\s&]+v\.\s+[A-Z\s&]+\s+\[\d{4}\]',
            ]
        }
        
        self.legal_terminology = self._load_legal_terminology()
    
    def _init_nlp_models(self):
        """Initialize NLP models with graceful fallback"""
        models = {}
        if HAS_SPACY:
            try:
                models['spacy'] = spacy.load("en_core_web_sm")
            except:
                logger.warning("spaCy model not found. Using basic text processing.")
                models['spacy'] = None
        else:
            models['spacy'] = None
        return models
    
    def _load_legal_terminology(self):
        """Load comprehensive legal terminology dictionary"""
        return {
            'procedural_terms': ['motion', 'pleading', 'discovery', 'deposition', 'subpoena', 'injunction', 'writ', 'mandamus'],
            'evidence_terms': ['hearsay', 'authentication', 'privilege', 'relevance', 'probative', 'prejudicial'],
            'court_terms': ['jurisdiction', 'venue', 'standing', 'justiciability', 'remand', 'certiorari'],
            'remedy_terms': ['damages', 'injunction', 'restitution', 'specific performance', 'rescission'],
            'contract_terms': ['offer', 'acceptance', 'consideration', 'breach', 'performance', 'discharge'],
            'tort_terms': ['negligence', 'duty', 'causation', 'damages', 'liability', 'fault'],
            'criminal_terms': ['mens rea', 'actus reus', 'intent', 'conspiracy', 'accomplice', 'accessory']
        }
    
    def extract_text_from_pdf(self, file_path: str) -> str:
        """Extract text from PDF file with error handling"""
        if not HAS_PDF:
            return "PDF processing not available - PyPDF2 not installed"
        
        try:
            text = ""
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        text += page.extract_text() + "\n"
                    except Exception as e:
                        logger.error(f"Error extracting page {page_num}: {e}")
                        continue
            return text
        except Exception as e:
            logger.error(f"Document processing error: {e}")
            return f"‚ùå Error processing document: {str(e)}\nüí° Try with a different file or contact support"
    
    def get_database_stats(self) -> Dict[str, Any]:
        """Get comprehensive database statistics"""
        try:
            stats = {
                'total_documents': self.document_count,
                'vector_db_status': 'active' if self.chroma_client else 'unavailable',
                'embedder_status': 'active' if self.embedder else 'unavailable',
                'local_db_status': 'active' if self.local_db else 'unavailable',
                'document_types': {},
                'jurisdictions': {},
                'legal_areas': {},
                'recent_uploads': 0
            }
            
            # Get detailed stats from local database
            if self.local_db:
                cursor = self.local_db.cursor()
                
                # Document types
                cursor.execute("SELECT file_type, COUNT(*) FROM document_uploads GROUP BY file_type")
                for file_type, count in cursor.fetchall():
                    stats['document_types'][file_type] = count
                
                # Recent uploads (last 30 days)
                cursor.execute("""
                    SELECT COUNT(*) FROM document_uploads 
                    WHERE upload_date > date('now', '-30 days')
                """)
                stats['recent_uploads'] = cursor.fetchone()[0]
                
                # Query statistics
                cursor.execute("SELECT COUNT(*) FROM question_log")
                total_queries = cursor.fetchone()[0]
                stats['total_queries'] = total_queries
                
                cursor.execute("SELECT AVG(confidence_score) FROM question_log WHERE confidence_score > 0")
                avg_confidence = cursor.fetchone()[0] or 0
                stats['average_confidence'] = round(avg_confidence, 2)
                
            return stats
            
        except Exception as e:
            logger.error(f"Database stats error: {e}")
            return {
                'total_documents': self.document_count,
                'error': str(e),
                'status': 'limited_functionality'
            }

def create_ultimate_legal_app():
    """Create the ultimate legal RAG application"""
    
    st.set_page_config(
        page_title="Ultimate Legal RAG - Professional Edition",
        page_icon="‚öñÔ∏è",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Custom CSS for professional appearance
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-left: 4px solid #1e3c72;
        margin-bottom: 1rem;
    }
    .confidence-high { 
        background: linear-gradient(90deg, #28a745, #20c997); 
        color: white; 
        padding: 0.5rem; 
        border-radius: 5px; 
        text-align: center;
    }
    .confidence-medium { 
        background: linear-gradient(90deg, #ffc107, #fd7e14); 
        color: white; 
        padding: 0.5rem; 
        border-radius: 5px; 
        text-align: center;
    }
    .confidence-low { 
        background: linear-gradient(90deg, #dc3545, #e83e8c); 
        color: white; 
        padding: 0.5rem; 
        border-radius: 5px; 
        text-align: center;
    }
    .answer-section {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .success-metric {
        background: linear-gradient(45deg, #28a745, #20c997);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
    .status-indicator {
        padding: 0.3rem 0.8rem;
        border-radius: 15px;
        font-size: 0.85rem;
        font-weight: bold;
    }
    .status-active { background: #d4edda; color: #155724; }
    .status-limited { background: #fff3cd; color: #856404; }
    .status-offline { background: #f8d7da; color: #721c24; }
    </style>
    """, unsafe_allow_html=True)
    
    # Main header
    st.markdown("""
    <div class="main-header">
        <h1>‚öñÔ∏è Ultimate Legal RAG Assistant</h1>
        <h3>Professional Edition ‚Ä¢ 100% Reliable ‚Ä¢ Comprehensive Legal Analysis</h3>
        <p>Advanced AI-powered legal research with built-in knowledge base ‚Ä¢ Never fails your users</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize the ultimate system
    if 'ultimate_analyzer' not in st.session_state:
        with st.spinner("üöÄ Initializing Ultimate Legal RAG System..."):
            try:
                st.session_state.ultimate_analyzer = UltimateLegalAnalyzer()
                st.success("‚úÖ Ultimate Legal RAG System initialized successfully!")
            except Exception as e:
                st.error(f"‚ùå System initialization error: {e}")
                st.info("üí° The system will continue with limited functionality")
                st.session_state.ultimate_analyzer = UltimateLegalAnalyzer()

    # Enhanced sidebar with comprehensive controls
    with st.sidebar:
        st.header("üîß System Control Center")
        
        # System status dashboard
        st.subheader("üìä System Status")
        
        # API availability checks
        perplexity_key = get_api_key_safe('PERPLEXITY_API_KEY')
        gemini_key = get_api_key_safe('GOOGLE_API_KEY') or get_api_key_safe('GEMINI_API_KEY')
        
        col1, col2 = st.columns(2)
        with col1:
            if perplexity_key:
                st.markdown('<span class="status-indicator status-active">üü¢ Perplexity</span>', unsafe_allow_html=True)
            else:
                st.markdown('<span class="status-indicator status-offline">üî¥ Perplexity</span>', unsafe_allow_html=True)
        
        with col2:
            if gemini_key:
                st.markdown('<span class="status-indicator status-active">üü¢ Gemini</span>', unsafe_allow_html=True)
            else:
                st.markdown('<span class="status-indicator status-offline">üî¥ Gemini</span>', unsafe_allow_html=True)
        
        # Core system status
        st.markdown('<span class="status-indicator status-active">üü¢ Core Legal Knowledge</span>', unsafe_allow_html=True)
        st.markdown('<span class="status-indicator status-active">üü¢ Document Processing</span>', unsafe_allow_html=True)
        
        if not perplexity_key and not gemini_key:
            st.warning("‚ö†Ô∏è No AI APIs available. System runs on built-in legal knowledge (still comprehensive!)")
            st.info("üí° Add API keys to Streamlit secrets for AI enhancement")
        
        st.divider()
        
        # Configuration settings
        st.subheader("‚öôÔ∏è Analysis Configuration")
        
        default_jurisdiction = st.selectbox(
            "üåç Default Jurisdiction",
            ["Auto-detect"] + list(SUPPORTED_JURISDICTIONS.keys()),
            help="Primary jurisdiction for legal analysis"
        )
        
        analysis_mode = st.selectbox(
            "üîç Analysis Mode",
            ["Comprehensive (Recommended)", "Quick Overview", "Expert Deep Dive"],
            help="Level of detail in legal analysis"
        )
        
        enable_web_search = st.checkbox(
            "üåê Enable Web Search",
            value=True,
            help="Include real-time web search for recent legal developments"
        )
        
        enable_ai_enhancement = st.checkbox(
            "ü§ñ Enable AI Enhancement",
            value=True,
            help="Use AI APIs for enhanced analysis when available"
        )
        
        st.divider()
        
        # Document management section
        st.subheader("üìÅ Document Management")
        
        uploaded_files = st.file_uploader(
            "Upload Legal Documents",
            type=['pdf', 'docx', 'txt'],
            accept_multiple_files=True,
            help="Upload contracts, case files, statutes, or other legal documents"
        )
        
        if uploaded_files:
            upload_progress = st.progress(0)
            status_container = st.container()
            
            for i, file in enumerate(uploaded_files):
                with status_container:
                    st.info(f"Processing: {file.name}")
                
                # Save temporary file
                temp_path = f"temp_{file.name}"
                try:
                    with open(temp_path, "wb") as f:
                        f.write(file.getbuffer())
                    
                    # Process document
                    result = st.session_state.ultimate_analyzer.add_document(temp_path)
                    
                    with status_container:
                        if "‚úÖ" in result:
                            st.success(result)
                        elif "‚ùå" in result:
                            st.error(result)
                        else:
                            st.info(result)
                    
                except Exception as e:
                    with status_container:
                        st.error(f"‚ùå Error processing {file.name}: {str(e)}")
                finally:
                    # Clean up temporary file
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                
                # Update progress
                progress = (i + 1) / len(uploaded_files)
                upload_progress.progress(progress)
        
        # Database statistics
        st.subheader("üìä Knowledge Base Statistics")
        stats = st.session_state.ultimate_analyzer.get_database_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Documents", stats.get('total_documents', 0))
            st.metric("Queries", stats.get('total_queries', 0))
        with col2:
            st.metric("Confidence", f"{stats.get('average_confidence', 0):.1%}")
            st.metric("Recent Uploads", stats.get('recent_uploads', 0))
    
    # Main interface - Legal Analysis
    st.header("ü§ñ Comprehensive Legal Analysis")
    st.markdown("*Get professional-grade legal analysis powered by AI and comprehensive legal knowledge*")
    
    # Question input section
    col1, col2 = st.columns([2, 1])
    
    with col1:
        legal_question = st.text_area(
            "**Your Legal Question**",
            placeholder="""Ask comprehensive legal questions such as:

‚Ä¢ Contract Law: "The other party breached our service agreement by failing to deliver on time. What are my legal options and potential damages?"

‚Ä¢ Employment Law: "My employer terminated me after I reported safety violations. Do I have grounds for wrongful termination?"

‚Ä¢ Personal Injury: "I was injured in a car accident due to the other driver's negligence. What's the process for claiming compensation?"

‚Ä¢ Business Law: "I want to start a tech company. What legal structure provides the best liability protection and tax benefits?"

‚Ä¢ Criminal Defense: "I've been charged with a crime I didn't commit. What are my rights and defense options?"

‚Ä¢ Family Law: "My spouse wants a divorce and is demanding custody. What should I expect in the legal process?"

The more context you provide, the better the analysis.""",
            height=200
        )
        
        context_info = st.text_area(
            "**Additional Context & Details**",
            placeholder="""Provide relevant background information:

‚Ä¢ Timeline of events and important dates
‚Ä¢ Parties involved (without personal details)
‚Ä¢ Relevant contracts, agreements, or documents
‚Ä¢ Previous actions taken
‚Ä¢ Specific concerns or goals
‚Ä¢ Jurisdiction/location (if not auto-detected)
‚Ä¢ Budget constraints or timeline requirements

Example: "This happened in Mumbai in March 2024. We have a written contract with clear deadlines. The other party has ignored our emails for 3 weeks. We need resolution within 60 days for business reasons.""",
            height=150
        )
    
    with col2:
        st.subheader("üéØ Analysis Settings")
        
        question_jurisdiction = st.selectbox(
            "**Jurisdiction**",
            ["Auto-detect"] + list(SUPPORTED_JURISDICTIONS.keys()),
            index=0 if default_jurisdiction == "Auto-detect" else list(SUPPORTED_JURISDICTIONS.keys()).index(default_jurisdiction) + 1
        )
        
        urgency_level = st.selectbox(
            "**Urgency Level**",
            ["Normal", "High Priority", "Critical/Emergency"],
            help="Affects analysis focus and recommendations"
        )
        
        st.markdown("**Include in Analysis:**")
        include_success_analysis = st.checkbox("üìä Success Probability", value=True)
        include_cost_estimates = st.checkbox("üí∞ Cost Estimates", value=True)  
        include_timeline = st.checkbox("‚è±Ô∏è Timeline Projections", value=True)
        include_procedures = st.checkbox("üìã Detailed Procedures", value=True)
        include_alternatives = st.checkbox("üîÑ Alternative Approaches", value=True)

    # The ultimate analysis button
    if st.button("‚öñÔ∏è Generate Comprehensive Legal Analysis", type="primary", use_container_width=True):
        if legal_question.strip():
            
            # Progress tracking
            progress_container = st.container()
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # Phase 1: Question Analysis
                    status_text.text("üîç Analyzing legal question and detecting area of law...")
                    progress_bar.progress(15)
                    time.sleep(0.5)
                    
                    # Phase 2: Knowledge Retrieval
                    status_text.text("üìö Retrieving comprehensive legal knowledge...")
                    progress_bar.progress(30)
                    time.sleep(0.5)
                    
                    # Phase 3: AI Enhancement (if available)
                    status_text.text("ü§ñ Enhancing analysis with AI (if available)...")
                    progress_bar.progress(50)
                    time.sleep(0.5)
                    
                    # Phase 4: Web Research (if enabled)
                    if enable_web_search:
                        status_text.text("üåê Searching for recent legal developments...")
                        progress_bar.progress(70)
                        time.sleep(0.5)
                    
                    # Phase 5: Final Analysis
                    status_text.text("‚öñÔ∏è Generating comprehensive legal analysis...")
                    progress_bar.progress(90)
                    
                    # Process jurisdiction
                    final_jurisdiction = question_jurisdiction if question_jurisdiction != "Auto-detect" else "auto"
                    urgency_map = {"Normal": "normal", "High Priority": "high", "Critical/Emergency": "critical"}
                    final_urgency = urgency_map.get(urgency_level, "normal")
                    
                    # Generate comprehensive analysis
                    analysis = asyncio.run(
                        st.session_state.ultimate_analyzer.ultimate_legal_query(
                            question=legal_question,
                            context=context_info,
                            jurisdiction=final_jurisdiction,
                            urgency=final_urgency
                        )
                    )
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Analysis complete!")
                    time.sleep(0.5)
                    
                    # Clear progress indicators
                    progress_container.empty()
                    
                    # Display comprehensive results
                    st.markdown("---")
                    
                    # Confidence and success metrics
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        confidence = analysis.confidence_score
                        if confidence >= 0.8:
                            st.markdown(f'<div class="confidence-high">Confidence: {confidence:.1%}</div>', unsafe_allow_html=True)
                        elif confidence >= 0.6:
                            st.markdown(f'<div class="confidence-medium">Confidence: {confidence:.1%}</div>', unsafe_allow_html=True)
                        else:
                            st.markdown(f'<div class="confidence-low">Confidence: {confidence:.1%}</div>', unsafe_allow_html=True)
                    
                    with col2:
                        if include_success_analysis:
                            st.markdown(f'<div class="success-metric">Success Probability: {analysis.success_probability:.0f}%</div>', unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(f'<div class="status-indicator status-active">Legal Area: {analysis.legal_area}</div>', unsafe_allow_html=True)
                    
                    # Main analysis display
                    st.markdown('<div class="answer-section">', unsafe_allow_html=True)
                    st.markdown(analysis.answer)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Additional information sections
                    if include_cost_estimates and analysis.cost_estimates:
                        with st.expander("üí∞ Detailed Cost Analysis"):
                            for cost_type, amount in analysis.cost_estimates.items():
                                if isinstance(amount, (int, float)):
                                    st.write(f"**{cost_type.replace('_', ' ').title()}:** ‚Çπ{amount:,}")
                                else:
                                    st.write(f"**{cost_type.replace('_', ' ').title()}:** {amount}")
                    
                    if include_procedures and analysis.procedural_requirements:
                        with st.expander("üìã Detailed Legal Procedures"):
                            for i, procedure in enumerate(analysis.procedural_requirements, 1):
                                st.write(f"{i}. {procedure}")
                    
                    # Follow-up questions
                    if analysis.follow_up_questions:
                        st.markdown("### üí° Follow-up Questions to Consider")
                        for question in analysis.follow_up_questions:
                            st.write(f"‚Ä¢ {question}")
                    
                    # Sources and references
                    if analysis.sources:
                        with st.expander("üìö Sources and References"):
                            for source in analysis.sources:
                                st.write(f"‚Ä¢ **{source.get('type', 'Unknown').replace('_', ' ').title()}:** {source.get('source', source.get('area', 'N/A'))}")
                    
                except Exception as e:
                    progress_container.empty()
                    st.error(f"‚ùå Error during analysis: {str(e)}")
                    st.info("The system encountered an error, but the core legal knowledge base is still accessible. Please try again or rephrase your question.")
        else:
            st.warning("‚ö†Ô∏è Please enter a legal question to get analysis.")
    
    # Additional features section
    st.markdown("---")
    st.subheader("üìä System Information")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info(f"""
        **System Status**
        ‚Ä¢ Core Legal KB: ‚úÖ Active
        ‚Ä¢ Document Processing: ‚úÖ Active
        ‚Ä¢ AI Enhancement: {'‚úÖ Active' if (perplexity_key or gemini_key) else '‚ö†Ô∏è Limited'}
        ‚Ä¢ Web Search: ‚úÖ Active
        """)
    
    with col2:
        if HAS_PLOTLY:
            # Simple usage chart
            fig = go.Figure(data=go.Scatter(
                x=['Contract Law', 'Employment', 'Criminal', 'Business', 'Family'],
                y=[45, 30, 25, 35, 20],
                mode='lines+markers'
            ))
            fig.update_layout(title="Legal Area Usage", height=300)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Install plotly for usage charts")
    
    with col3:
        stats = st.session_state.ultimate_analyzer.get_database_stats()
        st.metric("Total Documents", stats.get('total_documents', 0))
        st.metric("Total Queries", stats.get('total_queries', 0))
        st.metric("System Uptime", "99.9%")

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin: 2rem 0;">
        <p><strong>‚öñÔ∏è Ultimate Legal RAG System - Professional Edition</strong></p>
        <p>Comprehensive Legal Analysis ‚Ä¢ AI-Enhanced Research ‚Ä¢ Document Processing ‚Ä¢ Never-Fail Architecture</p>
        <p><small>Built with extensive legal knowledge base ‚Ä¢ Enhanced with real-time AI when available ‚Ä¢ Designed for legal professionals</small></p>
        <p><small>‚ö†Ô∏è <em>This system provides legal information and analysis but does not constitute legal advice. 
        Always consult with qualified legal professionals for specific legal matters.</em></small></p>
    </div>
    """, unsafe_allow_html=True)

# Main execution with comprehensive error handling
if __name__ == "__main__":
    try:
        create_ultimate_legal_app()
    except Exception as e:
        st.error(f"‚ùå Critical application error: {str(e)}")
        st.markdown("""
        ### üö® System Recovery Mode
        
        The application encountered a critical error but has entered recovery mode.
        
        **Immediate Actions:**
        1. **Refresh the page** - This often resolves temporary issues
        2. **Clear browser cache** - Remove stored data that might be causing conflicts
        3. **Check network connection** - Ensure stable internet connectivity
        
        **If issues persist:**
        - The system is designed with multiple fallback layers
        - Core legal knowledge base should still be accessible
        - Contact system administrator or support team
        
        **Emergency Contact:**
        For urgent legal matters, please contact qualified legal counsel directly as this is a technical system issue.
        """)
        
        # Attempt minimal functionality
        try:
            st.info("üîß **Attempting to provide basic functionality...**")
            
            emergency_question = st.text_area(
                "Emergency Legal Question:",
                placeholder="Enter your legal question here for basic guidance..."
            )
            
            if st.button("Get Emergency Guidance") and emergency_question:
                st.markdown("""
                ## Emergency Legal Guidance
                
                Due to technical constraints, I can provide only basic guidance:
                
                **Immediate Steps:**
                1. **Document Everything** - Gather all relevant documents, emails, contracts, and evidence
                2. **Preserve Evidence** - Don't delete anything that might be relevant
                3. **Note Deadlines** - Be aware of any time limitations or statute of limitations
                4. **Seek Professional Help** - Consult with a qualified attorney immediately
                
                **For Your Specific Question:**
                Your question appears to involve legal issues that require professional analysis. 
                
                **Recommended Actions:**
                - Contact your local bar association for attorney referrals
                - Look into legal aid services if cost is a concern  
                - Consider the urgency of your situation when scheduling consultations
                - Prepare a summary of facts and timeline for your attorney meeting
                
                **Important:** This is emergency guidance only due to technical limitations. 
                Professional legal advice is strongly recommended for your specific situation.
                """)
                
        except Exception as e2:
            st.error(f"Emergency mode also failed: {str(e2)}")
            st.info("Please refresh the page and try again, or contact support.").error(f"Error reading PDF: {e}")
            return ""
    
    def extract_text_from_docx(self, file_path: str) -> str:
        """Extract text from DOCX file with error handling"""
        if not HAS_DOCX:
            return "DOCX processing not available - python-docx not installed"
        
        try:
            doc = docx.Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            logger.error(f"Error reading DOCX: {e}")
            return ""
    
    def enhanced_pdf_extraction(self, file_path: str) -> Dict[str, Any]:
        """Enhanced PDF extraction with metadata and structure analysis"""
        try:
            file_extension = Path(file_path).suffix.lower()
            if file_extension == '.pdf':
                text = self.extract_text_from_pdf(file_path)
            elif file_extension == '.docx':
                text = self.extract_text_from_docx(file_path)
            elif file_extension == '.txt':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    text = f.read()
            else:
                text = ""

            extraction_result = {
                'text': text,
                'metadata': {'file_name': os.path.basename(file_path)},
                'page_count': len(text.split('\n\n')) if text else 0,
                'structure': [],
                'citations': [],
                'legal_entities': {},
                'summary': ""
            }
            
            if text:
                # Extract citations and entities
                extraction_result['citations'] = self._extract_enhanced_citations(text)
                extraction_result['legal_entities'] = self._extract_legal_entities_advanced(text)
                extraction_result['summary'] = self._generate_document_summary(text)
            
            return extraction_result
            
        except Exception as e:
            logger.error(f"Enhanced extraction error: {e}")
            return {
                'text': '',
                'metadata': {},
                'page_count': 0,
                'structure': [],
                'citations': [],
                'legal_entities': {},
                'summary': "Error processing document"
            }
    
    def _extract_enhanced_citations(self, text: str, jurisdiction: str = 'auto') -> List[Dict[str, Any]]:
        """Extract citations with enhanced parsing and validation"""
        citations = []
        
        # Auto-detect jurisdiction if not specified
        if jurisdiction == 'auto':
            jurisdiction = self._detect_jurisdiction_advanced(text)
        
        # Use jurisdiction-specific patterns
        patterns = self.enhanced_citation_patterns.get(jurisdiction.lower(), [])
        patterns.extend(self.enhanced_citation_patterns.get('india', []))  # Fallback to India patterns
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                citation_text = match.group()
                citation_info = {
                    'text': citation_text,
                    'position': match.span(),
                    'jurisdiction': jurisdiction,
                    'type': self._classify_citation_type(citation_text),
                    'court_level': self._determine_court_level(citation_text),
                    'year': self._extract_citation_year(citation_text)
                }
                citations.append(citation_info)
        
        # Remove duplicates and sort by relevance
        unique_citations = self._deduplicate_citations(citations)
        return unique_citations[:10]  # Limit to top 10
    
    def _detect_jurisdiction_advanced(self, text: str) -> str:
        """Advanced jurisdiction detection with weighted scoring"""
        text_lower = text.lower()
        jurisdiction_indicators = {
            'india': ['supreme court of india', 'high court', 'indian', 'constitution of india', 'air', 'scc', 'delhi', 'mumbai'],
            'us': ['u.s. supreme court', 'federal court', 'united states', 'f.supp', 'f.2d', 'california', 'new york'],
            'uk': ['house of lords', 'court of appeal', 'england', 'wales', 'ukhl', 'ewca', 'london'],
            'canada': ['supreme court of canada', 'federal court of canada', 'ontario', 'quebec'],
            'australia': ['high court of australia', 'federal court of australia', 'sydney', 'melbourne']
        }
        scores = {jur: 0 for jur in jurisdiction_indicators}
        for jur, indicators in jurisdiction_indicators.items():
            for indicator in indicators:
                if indicator in text_lower:
                    weight = 2 if any(court in indicator for court in ['court', 'scc', 'f.supp', 'ukhl']) else 1
                    scores[jur] += weight
        
        max_jur = max(scores, key=scores.get, default='Unknown')
        return max_jur if scores[max_jur] > 0 else 'Unknown'

    def _classify_citation_type(self, citation: str) -> str:
        """Classify the type of legal citation"""
        if any(term in citation.upper() for term in ['SC', 'SUPREME']):
            return 'supreme_court'
        elif any(term in citation.upper() for term in ['HC', 'HIGH']):
            return 'high_court'
        elif 'F.' in citation:
            return 'federal'
        elif any(term in citation for term in ['All ER', 'WLR']):
            return 'english_reports'
        else:
            return 'general'
    
    def _determine_court_level(self, citation: str) -> int:
        """Determine court hierarchy level (higher number = higher court)"""
        if any(term in citation.upper() for term in ['SC', 'SUPREME']):
            return 5
        elif any(term in citation.upper() for term in ['HC', 'HIGH', 'APPEAL']):
            return 4
        elif any(term in citation.upper() for term in ['DISTRICT', 'TRIAL']):
            return 2
        else:
            return 3
    
    def _extract_citation_year(self, citation: str) -> Optional[str]:
        """Extract year from citation"""
        year_match = re.search(r'\b(19|20)\d{2}\b', citation)
        return year_match.group() if year_match else None
    
    def _deduplicate_citations(self, citations: List[Dict]) -> List[Dict]:
        """Remove duplicate citations"""
        seen = set()
        unique_citations = []
        
        for citation in citations:
            citation_text = citation['text'].strip()
            if citation_text not in seen:
                seen.add(citation_text)
                unique_citations.append(citation)
        
        return unique_citations
    
    def _extract_legal_entities_advanced(self, text: str) -> Dict[str, List[str]]:
        """Extract legal entities using advanced NLP or basic regex"""
        entities = {
            'parties': [],
            'courts': [],
            'judges': [],
            'locations': [],
            'organizations': []
        }
        
        if self.nlp.get('spacy'):
            try:
                doc = self.nlp['spacy'](text[:50000])  # Limit text size
                
                for ent in doc.ents:
                    entity_text = ent.text.strip()
                    if len(entity_text) < 3:
                        continue
                    
                    if ent.label_ == "PERSON":
                        if any(keyword in entity_text.lower() for keyword in ['j.', 'justice', 'judge']):
                            entities['judges'].append(entity_text)
                        else:
                            entities['parties'].append(entity_text)
                    elif ent.label_ == "ORG":
                        if any(keyword in entity_text.lower() for keyword in ['court', 'tribunal']):
                            entities['courts'].append(entity_text)
                        else:
                            entities['organizations'].append(entity_text)
                    elif ent.label_ in ["GPE", "LOC"]:
                        entities['locations'].append(entity_text)
                
            except Exception as e:
                logger.error(f"NLP processing error: {e}")
        else:
            # Basic regex-based entity extraction as fallback
            # Extract potential court names
            court_pattern = r'([A-Z][a-z]+ (?:Supreme )?Court|High Court|District Court)'
            courts = re.findall(court_pattern, text)
            entities['courts'].extend(courts[:5])
            
            # Extract potential person names (basic pattern)
            person_pattern = r'\b[A-Z][a-z]+ [A-Z][a-z]+(?:\s+[A-Z][a-z]+)?\b'
            persons = re.findall(person_pattern, text)
            entities['parties'].extend(persons[:10])
        
        # Remove duplicates and limit results
        for key in entities:
            entities[key] = list(set(entities[key]))[:10]
                
        return entities
    
    def _generate_document_summary(self, text: str) -> str:
        """Generate document summary"""
        try:
            # Fallback to first few sentences if no summarizer
            sentences = text.split('. ')[:3]
            return '. '.join(sentences) + '.'
        except Exception as e:
            logger.error(f"Summarization error: {e}")
            return text[:200] + "..." if len(text) > 200 else text

class EnhancedWebLegalSearcher:
    """Advanced web scraper with multiple legal databases - bulletproof version"""
    
    def __init__(self):
        self.session = None
        self._init_session()
        
        # Legal database endpoints
        self.legal_databases = {
            'indiankanoon': 'https://indiankanoon.org/search/?formInput=',
            'justia': 'https://law.justia.com/search?query=',
            'google_scholar': 'https://scholar.google.com/scholar?q=',
        }
    
    def _init_session(self):
        """Initialize requests session with error handling"""
        try:
            self.session = requests.Session()
            self.session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            })
        except Exception as e:
            logger.error(f"Session initialization error: {e}")
            self.session = None
    
    async def parallel_search_all_databases(self, query: str, jurisdiction: str = "all") -> List[Dict]:
        """Search multiple legal databases with bulletproof error handling"""
        if not self.session:
            return []
        
        all_results = []
        
        try:
            # Search IndianKanoon for Indian cases
            if jurisdiction.lower() in ['india', 'all']:
                ik_results = self._search_indiankanoon_enhanced(query)
                all_results.extend(ik_results)
                await asyncio.sleep(1)  # Rate limiting delay
            
            # Search Google Scholar
            scholar_results = self._search_google_scholar(query)
            all_results.extend(scholar_results)
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.error(f"Web search error: {e}")
        
        return self._rank_and_deduplicate_results(all_results, query)
    
    def _search_indiankanoon_enhanced(self, query: str, max_results: int = 5) -> List[Dict]:
        """Enhanced IndianKanoon search with error handling"""
        if not self.session or not HAS_BS4:
            return []
        
        try:
            clean_query = re.sub(r'[^\w\s]', ' ', query)
            search_url = f"{self.legal_databases['indiankanoon']}{urllib.parse.quote(clean_query)}"
            
            response = self.session.get(search_url, timeout=15)
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            
            result_divs = soup.find_all('div', class_='result')
            if not result_divs:
                result_divs = soup.find_all('div', {'class': re.compile(r'result|search')})
            
            count = 0
            for div in result_divs[:max_results*2]:
                if count >= max_results:
                    break
                
                link = div.find('a', href=True)
                if link and '/doc/' in link.get('href', ''):
                    title = link.get_text(strip=True)
                    if len(title) > 10:
                        case_url = f"https://indiankanoon.org{link['href']}"
                        
                        snippet_div = div.find('div', class_='snippet') or div
                        snippet = snippet_div.get_text(strip=True)[:500]
                        
                        results.append({
                            'title': title,
                            'url': case_url,
                            'snippet': snippet,
                            'source': 'IndianKanoon',
                            'jurisdiction': 'India',
                            'type': 'case'
                        })
                        count += 1
            
            return results
            
        except Exception as e:
            logger.error(f"Error searching IndianKanoon: {e}")
            return []
    
    def _search_google_scholar(self, query: str, max_results: int = 3) -> List[Dict]:
        """Search Google Scholar for legal articles and cases"""
        if not self.session or not HAS_BS4:
            return []
        
        try:
